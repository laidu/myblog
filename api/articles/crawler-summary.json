{"title":"crawler-summary","slug":"crawler-summary","date":"2017-12-21T02:00:48.000Z","updated":"2018-02-11T06:22:43.327Z","comments":true,"path":"api/articles/crawler-summary.json","excerpt":null,"covers":["/myblog/2017/12/21/crawler-summary/webmagic.png"],"content":"<p>#1.爬虫分类</p>\n<ul>\n<li><p>数据爬虫</p>\n<ul>\n<li>深度爬虫<ul>\n<li>页面爬虫<ul>\n<li>静态页面</li>\n<li>动态页面</li>\n</ul>\n</li>\n<li>接口类爬虫<ul>\n<li>网站接口</li>\n<li>app接口</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>垂直爬虫</li>\n</ul>\n</li>\n<li><p>业务爬虫</p>\n</li>\n</ul>\n<p>#2.爬虫问题</p>\n<p>##2.1 目标</p>\n<ul>\n<li>断点续爬</li>\n<li>分布式部署</li>\n<li>监控报警<ul>\n<li>服务进程</li>\n<li>成功率</li>\n<li>改版</li>\n</ul>\n</li>\n<li>无缝发版</li>\n<li>服务高可用</li>\n<li>并发</li>\n</ul>\n<p>##2.2 爬虫中的问题</p>\n<ul>\n<li>数据包获取</li>\n<li>封IP，请求次数限制</li>\n<li>验证码限制</li>\n<li>页面动态渲染</li>\n<li>请求重定向</li>\n<li>失败重爬</li>\n<li>爬虫结果返回</li>\n<li>cookies信息维护</li>\n<li>单点登录</li>\n<li>数据加密<ul>\n<li>js 加密</li>\n<li>app 加密<ul>\n<li>apk加壳</li>\n<li>native方法加密</li>\n<li>自定义加密</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>系统陈旧、数据复杂。。。</li>\n</ul>\n<p>#3.解决方案</p>\n<p>##3.1 工具</p>\n<p>###3.1.1 抓包工具</p>\n<ul>\n<li>chrome dev-tool</li>\n<li>burp site</li>\n<li>charles</li>\n</ul>\n<p>###3.1.2 逆向工具</p>\n<ul>\n<li>apktool</li>\n<li>enjarify</li>\n<li>jd-gui/jadx-gui</li>\n<li>android studio</li>\n<li>ida</li>\n<li>xposed</li>\n</ul>\n<p>##3.2开发组件</p>\n<p>###3.2.1 基础框架 <a href=\"https://github.com/Geek-Union/alpha.git\" rel=\"external nofollow noopener noreferrer\" target=\"_blank\">alpha</a></p>\n<p>###3.2.2 爬虫框架 <a href=\"https://github.com/code4craft/webmagic\" rel=\"external nofollow noopener noreferrer\" target=\"_blank\">webmagic</a></p>\n<blockquote>\n<p>WebMagic项目代码分为核心和扩展两部分。核心部分(webmagic-core)是一个精简的、模块化的爬虫实现，而扩展部分则包括一些便利的、实用性的功能。WebMagic的架构设计参照了Scrapy，目标是尽量的模块化，并体现爬虫的功能特点。<br>webmagic 总体架构:<br>  <img src=\"/myblog/2017/12/21/crawler-summary/webmagic.png\" alt=\"\"></p>\n</blockquote>\n<p>###3.2.3 消息组件 rabbitmq</p>\n<ul>\n<li>利用ack机制，确保消息被正确消耗，达到断点续爬</li>\n<li>新旧爬虫监听同个队列确保服务的无缝发版</li>\n<li>实现爬虫的分布式部署</li>\n<li>使用定制的spring－rabbitmq模块实现接口类爬虫的rpc调用</li>\n</ul>\n<p>###3.2.4 服务注册 zookeeper</p>\n<ul>\n<li>服务注册中心，实现爬虫服务的注册与发现</li>\n</ul>\n<p>###3.2.5 缓存 redis</p>\n<ul>\n<li>缓存可用代理IP</li>\n<li>缓存ip黑名单信息</li>\n<li>同步zookeeper中爬虫服务节点信息，减少zookeeper压力</li>\n<li>缓存爬虫配置信息</li>\n</ul>\n<p>###3.2.6 代理池维护</p>\n<p>###3.2.7 nginx</p>\n<blockquote>\n<p>通过nginx的流量切换实现爬虫服务API层无缝发版</p>\n</blockquote>\n<p>##3.3第三方服务</p>\n<p>###3.3.1 打码服务</p>\n<ul>\n<li><a href=\"https://github.com/tesseract-ocr\" rel=\"external nofollow noopener noreferrer\" target=\"_blank\">tesseract-ocr</a>(开源)<blockquote>\n<p>一款由HP实验室开发由Google维护的开源OCR（Optical Character Recognition , 光学字符识别）引擎，与Microsoft Office Document Imaging（MODI）相比，我们可以不断的训练的库，使图像转换文本的能力不断增强；如果团队深度需要，还可以以它为模板，开发出符合自身需求的OCR引擎。</p>\n</blockquote>\n</li>\n<li><a href=\"http://www.chaojiying.com/\" rel=\"external nofollow noopener noreferrer\" target=\"_blank\">超级鹰</a>（收费）</li>\n</ul>\n<p>###3.3.2 代理池服务</p>\n<ul>\n<li><a href=\"https://www.abuyun.com/\" rel=\"external nofollow noopener noreferrer\" target=\"_blank\">阿布云</a>（单一代理IP）</li>\n<li><a href=\"http://www.data5u.com/\" rel=\"external nofollow noopener noreferrer\" target=\"_blank\">无忧</a>（返回代理IP列表）</li>\n<li><a href=\"\">adsl主机</a>（返回代理IP列表）</li>\n</ul>\n<p>##3.4 apk逆向</p>\n<ul>\n<li>抓包</li>\n<li>smali动态调试</li>\n<li>dump内存信息</li>\n<li>hook String 构造函数</li>\n<li>创建android httpServer 提供so加密服务</li>\n</ul>\n<p>#4.爬虫优化</p>\n<p>##4.1 初次优化–爬虫框架异步优化，替换结果接口类爬虫结果汇总策略</p>\n<ul>\n<li>使用asyncHttpClient代替httpclient</li>\n<li>引入rabbitmq的RPC，消除因服务器系统时间不一致而造成的爬虫结果汇总bug</li>\n</ul>\n<p>##4.2 再次优化–rabbitmq、日志优化、部署优化</p>\n<ul>\n<li>把爬虫服务按一定规则分组，减少对列和消费者数量</li>\n<li>超时时间在小范围内随机，使rabbitmq消息结果返回更”均匀”</li>\n<li>优化日志,调整队列大小、使用异步方式打印日志</li>\n</ul>\n<p>##4.3 第三次优化–服务接口优化</p>\n<p>#5.爬虫监控</p>\n<p>##5.1 服务器监控</p>\n<blockquote>\n<p>使用nagios监控</p>\n<ul>\n<li>服务进程</li>\n<li>内存信息</li>\n<li>磁盘占用情况</li>\n</ul>\n</blockquote>\n<p>##5.2 日志分类</p>\n<ul>\n<li>nginx日志<ul>\n<li>修改nginx日志打印格式为json</li>\n</ul>\n</li>\n<li>程序日志<ul>\n<li>API使用MDC加入请求uuid信息，</li>\n<li>编写注解打印关键方法执行信息日志</li>\n<li>普通日志</li>\n</ul>\n</li>\n</ul>\n<p>##5.3 ELK流程</p>\n<blockquote>\n<p>logstash -&gt; kafka -&gt; logstash -&gt; es(x=pack) -&gt; kinaba</p>\n</blockquote>\n<ul>\n<li>日志监控报警</li>\n<li>爬虫请求、成功率、图表展示</li>\n</ul>\n<p>#6.常用反爬策略</p>\n<ul>\n<li>Heaader<ul>\n<li>User-Agent</li>\n<li>Accept-Charset</li>\n<li>Cookie</li>\n<li>Content-Type</li>\n<li>Referer</li>\n</ul>\n</li>\n<li>Cookies验证</li>\n<li>ip限制</li>\n<li>验证码<ul>\n<li>字符识别验证</li>\n<li>简单四则运算</li>\n<li>滑块验证</li>\n</ul>\n</li>\n<li>常用数据加密算法<ul>\n<li>Base64编码</li>\n<li>MD5</li>\n<li>AES</li>\n<li>DES</li>\n<li>DESede</li>\n<li>RSA</li>\n</ul>\n</li>\n</ul>\n","categories":[],"tags":[{"name":"summary","path":"api/tags/summary.json"}]}